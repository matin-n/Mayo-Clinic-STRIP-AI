{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Transfer Learning Submission"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import gc\n",
    "import glob\n",
    "import os\n",
    "from glob import glob\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import pyvips\n",
    "import skimage.io as io\n",
    "from keras.models import load_model\n",
    "from PIL import Image\n",
    "from skimage.color import rgb2gray, rgba2rgb\n",
    "from skimage.filters.thresholding import threshold_otsu\n",
    "from skimage.util import img_as_ubyte\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras.applications.efficientnet import preprocess_input\n",
    "from tensorflow.keras.preprocessing import image as image_utils\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "from tqdm.auto import trange\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Helper Function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def pre_process_data(path, save_path):\n",
    "    \"\"\"Reads in the data from the path and saves the image to disk.\"\"\"\n",
    "    try:\n",
    "        # 1792x1792 crop was used for training. I did not have enough time to evaluate the impact of using 896x896 on test data.\n",
    "        img = pyvips.Image.thumbnail(path, 896, crop=\"attention\")\n",
    "  \n",
    "        image = np.ndarray(\n",
    "            buffer=img.write_to_memory(),            \n",
    "            shape=[img.height, img.width, img.bands],\n",
    "        )\n",
    "\n",
    "        # Thresholding the image\n",
    "        image_gray = rgb2gray(image)\n",
    "        # Find threshold between background and foreground\n",
    "        thresh = threshold_otsu(image_gray)\n",
    "        binary = image_gray <= thresh\n",
    "        # Source: https://stackoverflow.com/questions/72239660/how-can-one-apply-a-mask-on-a-numpy-array-which-leaves-the-original-values-uncha\n",
    "        image = image[:, :, ...] * binary[..., None]\n",
    "\n",
    "        # Remove regions with no signal.\n",
    "        # Source: https://www.kaggle.com/code/abhishek123maurya/image-cropping-without-altering-pixel-values\n",
    "        # Iterate through \"rows\" of the image.\n",
    "        rm = [i for i in range(image.shape[0]) if len(np.unique(image[i, :])) <= 75]\n",
    "        img = np.delete(image, rm, axis=0)\n",
    "        # Iterate through \"columns\" of the image.\n",
    "        rm = [i for i in range(image.shape[1]) if len(np.unique(image[:, i])) <= 75]\n",
    "        img = np.delete(image, rm, axis=1)\n",
    "\n",
    "        io.imsave(save_path, image, quality=100)\n",
    "    finally:\n",
    "        del rm\n",
    "        del binary\n",
    "        del image_gray\n",
    "        del image\n",
    "        del img\n",
    "        gc.collect()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Process Images\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the test data.\n",
    "test_df = pd.read_csv(\"../input/mayo-clinic-strip-ai/test.csv\")\n",
    "\n",
    "# Save images to current directory for inference.\n",
    "os.mkdir(\"./scaled_images\")\n",
    "\n",
    "# Crop and resize images.\n",
    "train_images = glob(\"../input/mayo-clinic-strip-ai/test/*.tif\")\n",
    "for i in trange(len(train_images)):\n",
    "    pre_process_data(\n",
    "        train_images[i],\n",
    "        train_images[i]\n",
    "        .replace(\"../input/mayo-clinic-strip-ai/test/\", \"./scaled_images/\")\n",
    "        .replace(\".tif\", \".jpeg\"),\n",
    "    )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Add file path of transformed images to dataframe.\n",
    "test_df[\"image\"] = test_df[\"image_id\"].apply(\n",
    "    lambda x: os.path.join(\"./scaled_images\", x + \".jpeg\")\n",
    ")\n",
    "test_df.head()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Make Predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load trained model.\n",
    "pretrained_model = load_model(\"../input/mayoclinic-efficientnetb4/TransferLearn_EfficientNet_Mayo.h5\")\n",
    "\n",
    "SIZE = 384\n",
    "datagen_valid = ImageDataGenerator(samplewise_center=True)\n",
    "\n",
    "def make_predictions(image_path):\n",
    "    image = image_utils.load_img(image_path, target_size=(384, 384))\n",
    "    image = image_utils.img_to_array(image)\n",
    "    image = image.reshape(1, SIZE, SIZE, 3)\n",
    "    image = datagen_valid.standardize(image)\n",
    "    preds = pretrained_model.predict(image)    \n",
    "    return preds\n",
    "\n",
    "# Save predictions to dataframe.\n",
    "df_predict_probas = pd.DataFrame()\n",
    "df_predict_probas[\"CE\"] = test_df[\"image\"].apply(lambda x: make_predictions(x)[0][0])\n",
    "df_predict_probas[\"LAA\"] = test_df[\"image\"].apply(lambda x: make_predictions(x)[0][1])\n",
    "\n",
    "# Merge predictions with patient_id.\n",
    "predictions = test_df.merge(df_predict_probas, left_index=True, right_index=True)\n",
    "\n",
    "# Columns for submission.\n",
    "predictions_clean = predictions[[\"patient_id\", \"CE\", \"LAA\"]]\n",
    "\n",
    "# Only one prediction per patient is allowed.\n",
    "submission = predictions_clean.sort_values(by=\"patient_id\").groupby(\"patient_id\").mean()\n",
    "\n",
    "# Save predictions to csv.\n",
    "submission.to_csv(\"submission.csv\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.7.12 ('python')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.7.12"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "33156c7f7ccf3a2565b628d4cedcfb009b502d3e308046f24b221e9d75da87b2"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
