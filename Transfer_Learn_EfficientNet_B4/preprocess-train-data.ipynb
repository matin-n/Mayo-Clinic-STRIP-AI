{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Preprocess Train Data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import gc\n",
    "import os\n",
    "from glob import glob\n",
    "\n",
    "import numpy as np\n",
    "import pyvips\n",
    "import skimage.io as io\n",
    "from PIL import Image\n",
    "from skimage.color import rgb2gray, rgba2rgb\n",
    "from skimage.filters.thresholding import threshold_otsu\n",
    "from skimage.util import img_as_ubyte\n",
    "from tqdm.auto import trange\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Helper Function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def pre_process_data(path, save_path):\n",
    "    \"\"\"Reads in the data from the path and saves the image to disk.\"\"\"\n",
    "    try:        \n",
    "        img = pyvips.Image.thumbnail(path, 1792, crop=\"attention\")\n",
    "  \n",
    "        image = np.ndarray(\n",
    "            buffer=img.write_to_memory(),            \n",
    "            shape=[img.height, img.width, img.bands],\n",
    "        )\n",
    "\n",
    "        # Thresholding the image\n",
    "        image_gray = rgb2gray(image)\n",
    "        # Find threshold between background and foreground\n",
    "        thresh = threshold_otsu(image_gray)\n",
    "        binary = image_gray <= thresh\n",
    "        # Source: https://stackoverflow.com/questions/72239660/how-can-one-apply-a-mask-on-a-numpy-array-which-leaves-the-original-values-uncha\n",
    "        image = image[:, :, ...] * binary[..., None]\n",
    "\n",
    "        # Remove regions with no signal.\n",
    "        # Source: https://www.kaggle.com/code/abhishek123maurya/image-cropping-without-altering-pixel-values\n",
    "        # Iterate through \"rows\" of the image.\n",
    "        rm = [i for i in range(image.shape[0]) if len(np.unique(image[i, :])) <= 75]\n",
    "        img = np.delete(image, rm, axis=0)\n",
    "        # Iterate through \"columns\" of the image.\n",
    "        rm = [i for i in range(image.shape[1]) if len(np.unique(image[:, i])) <= 75]\n",
    "        img = np.delete(image, rm, axis=1)\n",
    "\n",
    "        io.imsave(save_path, image, quality=100)\n",
    "    finally:\n",
    "        del rm\n",
    "        del binary\n",
    "        del image_gray\n",
    "        del image\n",
    "        del img\n",
    "        gc.collect()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Process Image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Make directory to save processed images.\n",
    "os.makedirs(\"train_data_cropped\", exist_ok=True)\n",
    "\n",
    "# Get the paths to each training image.\n",
    "train_images = glob(\"../input/mayo-clinic-strip-ai/train/*.tif\")\n",
    "\n",
    "# Preprocess the training images and save each iamge.\n",
    "for i in trange(len(train_images)):\n",
    "    pre_process_data(train_images[i], train_images[i].replace(\"../input/mayo-clinic-strip-ai/train/\", \"./train_data_cropped/\").replace(\".tif\", \".jpeg\")) \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Zip the images into a single archive.\n",
    "!zip -r images.zip *.jpeg\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.7.12 ('python')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.7.12"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "33156c7f7ccf3a2565b628d4cedcfb009b502d3e308046f24b221e9d75da87b2"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
