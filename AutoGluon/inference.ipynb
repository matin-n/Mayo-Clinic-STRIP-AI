{"cells":[{"cell_type":"markdown","metadata":{},"source":["# AutoGluon Submission"]},{"cell_type":"markdown","metadata":{},"source":["## Imports"]},{"cell_type":"code","execution_count":null,"metadata":{"_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","trusted":true},"outputs":[],"source":["import gc\n","import os\n","from multiprocessing.dummy import Pool\n","\n","import pandas as pd\n","import pyvips\n","from autogluon.vision import ImagePredictor\n"]},{"cell_type":"markdown","metadata":{},"source":["## Environment Variables"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["# Assumption that this is a Kaggle environment.\n","INPUT_DIRECTORY = \"../input/mayo-clinic-strip-ai\"\n","TEST_IMAGE_DIR = \"../input/mayo-clinic-strip-ai/test\"\n","IMAGE_OUTPUT_DIRECTORY = \"/kaggle/working/scaled_images\"\n","MODEL_PATH = \"../input/autogluon052-standalone-and-model/model-01.ag\"\n"]},{"cell_type":"markdown","metadata":{},"source":["## Helper Functions"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["def preprocess_image(image_id, maxw, maxh):\n","\n","    # Image is resized to maxw x maxh, smart cropped, and then saved to disk as a JPEG.\n","\n","    # The smart crop is applied with attention features.\n","    # Other options: https://libvips.github.io/pyvips/enums.html#pyvips.enums.Interesting\n","\n","    out = pyvips.Image.thumbnail(\n","        os.path.join(TEST_IMAGE_DIR, image_id + \".tif\"),\n","        maxw,\n","        height=maxh,\n","        crop=\"attention\",\n","    )\n","    out.write_to_file(os.path.join(IMAGE_OUTPUT_DIRECTORY, image_id + \".jpeg\"), Q=100)\n","    del out\n","    gc.collect\n","\n","def save_dataset(num_workers, iterable):\n","    # Enable verbose logging.\n","    os.environ[\"VIPS_PROGRESS\"] = \"1\"\n","    # Limit pyvips to two threads.\n","    os.environ[\"VIPS_CONCURRENCY\"] = \"2\"\n","\n","    pool = Pool(num_workers)\n","    results = pool.starmap(preprocess_image, iterable)\n","    pool.close()\n","    pool.join()\n","    "]},{"cell_type":"markdown","metadata":{},"source":["## Process Images"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":[" # Load the test data, used for evaluation.\n","test_df = pd.read_csv(f\"{INPUT_DIRECTORY}/test.csv\")\n","\n","# Resize images, apply smart crop, and save to disk.\n","# Source: https://github.com/libvips/pyvips/issues/291#issuecomment-994714555\n","image_ids = test_df[\"image_id\"]\n","max_width = 1024\n","max_height = 1024\n","iter = [(image_id, max_width, max_height) for image_id in image_ids]\n","save_dataset(num_workers=3, iterable=iter)\n","\n","# Add file path of transformed images to dataframe.\n","test_df[\"image\"] = test_df[\"image_id\"].apply(\n","    lambda x: os.path.join(IMAGE_OUTPUT_DIRECTORY, x + \".jpeg\")\n",")\n"]},{"cell_type":"markdown","metadata":{},"source":["## Make Predictions"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["# Load model.\n","trained_model = ImagePredictor.load(\n","    path=MODEL_PATH\n",")\n","\n","# Make predictions.\n","df_predict_probas = trained_model.predict_proba(test_df).rename(\n","    columns={1: \"LAA\", 0: \"CE\"}\n",")\n","\n","# Merge predictions with original dataframe.\n","predictions = test_df.merge(df_predict_probas, left_index=True, right_index=True)\n","\n","# Columns for submission requires patient_id, LAA, and CE.\n","submisson = predictions[[\"patient_id\", \"CE\", \"LAA\"]]\n","\n","# Only one prediction per patient is allowed. So, we take the average of the predictions for each patient.\n","final_submission = (\n","    submisson.sort_values(by=\"patient_id\").groupby(\"patient_id\").mean()\n",")\n","\n","# Save predictions.\n","final_submission.to_csv(\"submission.csv\")\n"]}],"metadata":{"kernelspec":{"display_name":"Python 3.7.12 ('python')","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.7.12"},"vscode":{"interpreter":{"hash":"33156c7f7ccf3a2565b628d4cedcfb009b502d3e308046f24b221e9d75da87b2"}}},"nbformat":4,"nbformat_minor":4}
