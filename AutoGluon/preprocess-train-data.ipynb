{"cells":[{"cell_type":"markdown","metadata":{},"source":["# Preprocess Train Data"]},{"cell_type":"markdown","metadata":{},"source":["## Imports"]},{"cell_type":"code","execution_count":null,"metadata":{"_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","trusted":true},"outputs":[],"source":["import gc\n","import os\n","import zipfile\n","from multiprocessing.dummy import Pool\n","\n","import pandas as pd\n","import pyvips\n"]},{"cell_type":"markdown","metadata":{},"source":["## Global Variables"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["# Assumption that this is a Kaggle environment.\n","INPUT_DIRECTORY = \"../input/mayo-clinic-strip-ai\"\n","TRAIN_IMAGE_DIR = \"../input/mayo-clinic-strip-ai/train\"\n"]},{"cell_type":"markdown","metadata":{},"source":["## Helper Function"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["def preprocess_image(image_id, maxw, maxh):\n","\n","    # Image is resized to maxw x maxh, smart cropped, and then saved to disk as a JPEG.\n","\n","    # The smart crop is applied with attention features.\n","    # Other options: https://libvips.github.io/pyvips/enums.html#pyvips.enums.Interesting\n","\n","    out = pyvips.Image.thumbnail(\n","        os.path.join(TRAIN_IMAGE_DIR, image_id + \".tif\"),\n","        maxw,\n","        height=maxh,\n","        crop=\"attention\",\n","    )\n","    out.write_to_file(image_id + \".jpeg\", Q=100)\n","    del out\n","    gc.collect\n","\n","\n","def save_dataset(num_workers, iterable):\n","\n","    # Enable verbose logging.\n","    os.environ[\"VIPS_PROGRESS\"] = \"1\"\n","    # Limit pyvips to two threads.\n","    os.environ[\"VIPS_CONCURRENCY\"] = \"2\"\n","\n","    # Source: https://github.com/libvips/pyvips/issues/291#issuecomment-994714555\n","    pool = Pool(num_workers)\n","    results = pool.starmap(preprocess_image, iterable)\n","    pool.close()\n","    pool.join()\n","    "]},{"cell_type":"markdown","metadata":{},"source":["## Process Images"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["train = pd.read_csv(f\"{INPUT_DIRECTORY}/train.csv\")\n","\n","# Resize images, apply smart crop, and save to disk in current directory.\n","image_ids = train[\"image_id\"]\n","max_width = 1024\n","max_height = 1024\n","iter = [(image_id, max_width, max_height) for image_id in image_ids]\n","save_dataset(num_workers=3, iterable=iter)\n"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["# Zip the images into a single archive.\n","with zipfile.ZipFile(\"images.zip\", \"w\") as zip:\n","    for file in os.listdir():\n","        if file.endswith(\".jpeg\"):\n","            zip.write(file)\n","\n","# Or use `zip -r images.zip *.jpeg`\n","# !zip -r images.zip *.jpeg\n"]}],"metadata":{"kernelspec":{"display_name":"Python 3.7.12 ('python')","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.7.12"},"vscode":{"interpreter":{"hash":"33156c7f7ccf3a2565b628d4cedcfb009b502d3e308046f24b221e9d75da87b2"}}},"nbformat":4,"nbformat_minor":4}
